{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f448b55e-e439-4239-9e35-719688ecca6e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "the thing is using .option(\"startingOffsets\", \"earliest\") option is crucial because by default spark does not read data from begining when it is reading from kafka .... \n",
    "so we need to specify the spark to read from start in kafka by the above mentioned option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "661226b2-5c9f-4eb6-a935-17e397f2327f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[1]: [FileInfo(path='dbfs:/user/hive/warehouse/mydb.db/', name='mydb.db/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/user/hive/warehouse/mytable/', name='mytable/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/user/hive/warehouse/sbit_db.db/', name='sbit_db.db/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/user/hive/warehouse/tararyen/', name='tararyen/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/user/hive/warehouse/targaryen/', name='targaryen/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/user/hive/warehouse/targaryen0/', name='targaryen0/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/user/hive/warehouse/targaryen1/', name='targaryen1/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/user/hive/warehouse/targaryen5/', name='targaryen5/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/user/hive/warehouse/targaryen6/', name='targaryen6/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/user/hive/warehouse/targaryend/', name='targaryend/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/user/hive/warehouse/targaryenp/', name='targaryenp/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/user/hive/warehouse/trial/', name='trial/', size=0, modificationTime=0)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls('dbfs:/user/hive/warehouse/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb903f5d-1a29-4254-b667-450641c31773",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "create table if not exists targaryenTemp1(\n",
    "  key BINARY,\n",
    "  value BINARY,\n",
    "  topic STRING,\n",
    "  partition INT,\n",
    "  offset LONG,\n",
    "  timestamp TIMESTAMP,\n",
    "  timestampType INT\n",
    ") using delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4328cd6a-e0a7-4f89-b163-dc21dc944b81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "kafka_server = \"pkc-4r087.us-west2.gcp.confluent.cloud:9092\"\n",
    "kafka_api_secret = \"SYRj4UPfB0qXJcYL32B+9FZYgT+SPsSlSyLA3Ww26v7NRxxLxBSdgP6A5Nqq842j\"\n",
    "base_dir_checkpoint = \"/project_stuff/checkpoint/\"\n",
    "kafka_api_key = \"PWEUCUXA4575GXRN\"\n",
    "\n",
    "df = (spark.readStream.format(\"kafka\") \n",
    "     .option(\"kafka.bootstrap.servers\", kafka_server) \n",
    "     .option(\"startingOffsets\", \"earliest\")\n",
    "     .option(\"kafka.security.protocol\", \"SASL_SSL\") \n",
    "     .option(\"kafka.sasl.jaas.config\", \"kafkashaded.org.apache.kafka.common.security.plain.PlainLoginModule required username='{}' password='{}';\".format(kafka_api_key, kafka_api_secret)) \n",
    "     .option(\"kafka.ssl.endpoint.identification.algorithm\", \"https\") \n",
    "     .option(\"kafka.sasl.mechanism\", \"PLAIN\") \n",
    "     .option(\"subscribe\",\"user_info_topic\") \n",
    "     .load()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae4468ac-2fc4-47a5-a039-94ae0f4ef9aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def upsert(df_micro_batch, batch_id):\n",
    "    df_micro_batch.createOrReplaceTempView(\"user_delta\")\n",
    "    query = f\"\"\"\n",
    "            MERGE INTO default.targaryenTest a\n",
    "            USING user_delta b\n",
    "            ON a.key = b.key\n",
    "            WHEN NOT MATCHED THEN INSERT *\n",
    "            \"\"\"\n",
    "    print(df_micro_batch.count())\n",
    "    df_micro_batch._jdf.sparkSession().sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a02f06f8-2417-4031-ae2a-f29c4e848007",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stream_writer = (df.writeStream \n",
    "                                 .format(\"delta\")\n",
    "                                #  .foreachBatch(upsert) \n",
    "                                 .option(\"checkpointLocation\", \"/gymgcs8jgjjgvjgchv1hvkyhvlc055test\") \n",
    "                                 .outputMode(\"append\") \n",
    "                                 .queryName(\"gym_logikhctkjhg1vhgjkhvhvcstream\")\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ff0bacb-ef43-4336-bb69-8d6be9c6200c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[36]: <pyspark.sql.streaming.query.StreamingQuery at 0x7f5c442b1460>"
     ]
    }
   ],
   "source": [
    "stream_writer.trigger(processingTime=\"10 minutes\").toTable('default.targaryenTemp1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5294c340-b709-4522-846c-053f871e141f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>count(1)</th></tr></thead><tbody><tr><td>13</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         13
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"__autoGeneratedAlias\":\"true\"}",
         "name": "count(1)",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select count(*) from default.targaryenTemp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63debc62-7477-4f08-8589-af7285929aaa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1664359751331570,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ReadStreamFromKafkaToDeltaTable",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
